---
layout: default
title:
---

<center><h1 class="smallcap">Research</h1></center>


<section>
        <!--<h2 class="small">Forthcoming Work</h2>
        </ul>

        <hr style="height:1px;width:80%;color:#D3D3Di3;background-color:#D3D3D3">
        -->
            <p><a href="https://dash.harvard.edu/handle/1/37375653" target="_blank" rel="noopener noreferrer">Statistical Inference for Adaptive Experimentation</a><br />
            <u>Kelly W. Zhang</u><br />
            <i>Ph.D. Thesis, 2023</i><br />
            [<a href="https://dash.harvard.edu/handle/1/37375653" target="_blank" rel="noopener noreferrer">pdf</a>]
            </p>


        <h2>Statistical Inference for Data Collected with RL Algorithms</h2>

        <ul style="list-style-type:disc">
        <li>
            <p><a href="https://dash.harvard.edu/handle/1/37375653" target="_blank" rel="noopener noreferrer">Statistical Inference for Adaptive Experimentation</a><br />
            <u>Kelly W. Zhang</u><br />
            <i>Ph.D. Thesis, 2023</i><br />
            [<a href="https://dash.harvard.edu/handle/1/37375653" target="_blank" rel="noopener noreferrer">pdf</a>]
            </p>
        </li>
        <li>
            <p><a href="https://arxiv.org/abs/2202.07098" target="_blank" rel="noopener noreferrer">Statistical Inference After Adaptive Sampling for Longitudinal Data</a><br/>
                <u>Kelly W. Zhang</u>, Lucas Janson, Susan A. Murphy<br/>
                <i>Under submission</i><br />
                [<a href="https://arxiv.org/abs/2202.07098" target="_blank" rel="noopener noreferrer">arXiv</a>]
            </p>
        </li>
        <li>
            <p><a href="https://proceedings.neurips.cc/paper/2021/hash/3d7d9461075eb7c37fbbfcad1d7042c1-Abstract.html" target="_blank" rel="noopener noreferrer">Statistical Inference with M-Estimators on Adaptively Collected Data</a><br />
            <u>Kelly W. Zhang</u>, Lucas Janson, Susan A. Murphy<br />
            <i>NeurIPS 2021</i><br />
            <span style="color:gray">Preliminary version at <i>ICML 2021 Workshop on Reinforcement Learning Theory</i></span><br />
            [<a href="https://arxiv.org/abs/2104.14074" target="_blank" rel="noopener noreferrer">arXiv</a>]
            [<a href="https://proceedings.neurips.cc/paper/2021/hash/3d7d9461075eb7c37fbbfcad1d7042c1-Abstract.html" target="_blank" rel="noopener noreferrer">proceedings</a>]
            [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9232184/" target="_blank" rel="noopener noreferrer">PubMed</a>]
            [<a href="https://www.youtube.com/watch?v=jflR7KOrqNA&t=2s" target="_blank" rel="noopener noreferrer">video</a>]
            [<a href="/assets/penn_state_2021_3.pdf" download>slides</a>]
            [<a href="/assets/NeurIPS_2021_poster.pdf" download>poster</a>]
            [<a href="https://github.com/kellywzhang/adaptively_weighted_Mestimation" target="_blank" rel="noopener noreferrer">code</a>]
            </p>
        </li>
        <li>
            <!--https://arxiv.org/abs/2002.03217-->
            <p><a href="https://proceedings.neurips.cc/paper/2020/hash/6fd86e0ad726b778e37cf270fa0247d7-Abstract.html" target="_blank" rel="noopener noreferrer">Inference for Batched Bandits</a><br />
            <u>Kelly W. Zhang</u>, Lucas Janson, Susan A. Murphy<br />
            <i>NeurIPS 2020</i><br />
            [<a href="https://arxiv.org/abs/2002.03217" target="_blank" rel="noopener noreferrer">arXiv</a>]
            [<a href="https://proceedings.neurips.cc/paper/2020/hash/6fd86e0ad726b778e37cf270fa0247d7-Abstract.html" target="_blank" rel="noopener noreferrer">proceedings</a>]
            [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8734616/" target="_blank" rel="noopener noreferrer">PubMed</a>]
            [<a href="https://www.youtube.com/watch?v=iLJ1hC5k-IQ" target="_blank" rel="noopener noreferrer">video</a>]
            [<a href="/assets/batched_bandits_presentation.pdf" download>slides</a>]
            [<a href="/assets/neurips_2020_poster.pdf" download>poster</a>]
            [<a href="https://github.com/kellywzhang/inference_batched_bandits" target="_blank" rel="noopener noreferrer">code</a>]
            </p>
            <!--[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8734616/" target="_blank" rel="noopener noreferrer">PubMed</a>]
            [<a href="/assets/quals_summary_doc.pdf" download>summary</a>]
                -->
            <!--[<a href="https://arxiv.org/abs/2002.03217">paper</a>] [<a href="/assets/neurips_2020_poster.pdf" download>poster</a>] [<a href="https://drive.google.com/file/d/10EkwIWubBdke5BK2uefza4beI6m6qMon/view?usp=sharing">video</a>] [<a href="https://github.com/kellywzhang/inference_batched_bandits">code</a>]</p>-->
        </li>
        </ul>

        <hr style="height:1px;width:80%;color:#D3D3Di3;background-color:#D3D3D3">

        <h2 class="small">Designing and Evaluating Reinforcement Learning Algorithms</h2>
        <ul style="list-style-type:disc">
        <li>
            <p><a href="https://arxiv.org/abs/2304.05365" target="_blank" rel="noopener noreferrer">Did we personalize? Assessing personalization by an online reinforcement learning algorithm using resampling</a><br />
            Susobhan Ghosh*, Raphael Kim*, Prasidh Chhabria, Raaz Dwivedi, Predrag Klasnja, Peng Liao, <u>Kelly W. Zhang</u>, Susan A. Murphy<br />
            <i>Machine Learning Journal: Special Issue on Reinforcement Learning for Real Life (to appear)</i><br />
            [<a href="https://arxiv.org/abs/2304.05365" target="_blank" rel="noopener noreferrer">arXiv</a>]
            </p>
        </li>
        <li>
            <p><a href="https://pubmed.ncbi.nlm.nih.gov/38307224/" target="_blank" rel="noopener noreferrer">Optimizing an adaptive Digital Oral Health Intervention for promoting Oral Self Care Behaviors: Micro-Randomized Trial Protocol</a><br />
            Inbal Nahum-Shani, Zara M. Greer, Anna L. Trella, <u>Kelly W. Zhang</u>, Stephanie Carpenter, David Elashoff, Susan A. Murphy, Vivek Shetty<br />
            <i>Contemporary Clinical Trials</i><br />
            [<a href="https://pubmed.ncbi.nlm.nih.gov/38307224/" target="_blank" rel="noopener noreferrer">PubMed</a>] 
            [<a href="https://classic.clinicaltrials.gov/ct2/show/NCT05624489" target="_blank" rel="noopener noreferrer">ClinicalTrials.gov</a>]
            </p>
        </li>
        <li>
            <p><a href="https://arxiv.org/abs/2208.07406" target="_blank" rel="noopener noreferrer">Reward Design For An Online Reinforcement Learning Algorithm Supporting Oral Self-Care</a><br />
            Anna L. Trella, <u>Kelly W. Zhang</u>, Inbal Nahum-Shani, Vivek Shetty, Finale Doshi-Velez, Susan A. Murphy<br />
            <i>Thirty-Fifth Annual Conference on Innovative Applications of Artificial Intelligence (IAAI-23)</i><br />
            [<a href="https://arxiv.org/abs/2208.07406" target="_blank" rel="noopener noreferrer">arXiv</a>]
            [<a href="https://github.com/StatisticalReinforcementLearningLab/oralytics_reward_design" target="_blank" rel="noopener noreferrer">code</a>]
            </p>
        </li>
        <li>
            <!--https://arxiv.org/abs/2206.03944-->
            <p><a href="https://www.mdpi.com/1999-4893/15/8/255" target="_blank" rel="noopener noreferrer">Designing Reinforcement Learning Algorithms for Digital Interventions: Pre-implementation Guidelines</a><br />
            Anna L. Trella, <u>Kelly W. Zhang</u>, Inbal Nahum-Shani, Vivek Shetty, Finale Doshi-Velez, Susan A. Murphy<br />
            <i>Algorithms (Special Issue "Algorithms in Decision Support Systems Vol. 2")</i><br />
            <span style="color:gray">Preliminary version at <i>RLDM 2022 (Multi-disciplinary Conference on RL and Decision Making); selected for an oral</i></span><br />
            [<a href="https://arxiv.org/abs/2206.03944" target="_blank" rel="noopener noreferrer">arXiv</a>]
            [<a href="https://www.mdpi.com/1999-4893/15/8/255" target="_blank" rel="noopener noreferrer">proceedings</a>]
            [<a href="https://github.com/StatisticalReinforcementLearningLab/pcs-for-rl" target="_blank" rel="noopener noreferrer">code</a>]
            </p>
        </li>
        <li>
            <!--https://drive.google.com/file/d/1DvB9vOnG6VerXLmEIWci4rNGent04g37/view-->
        </li>
        </ul>
        
        <hr style="height:1px;width:80%;color:#D3D3Di3;background-color:#D3D3D3">
            
        
        <p><a href="http://arxiv.org/abs/2208.00250" target="_blank" rel="noopener noreferrer">A Bayesian Approach to Learning Bandit Structure in Markov Decision Processes</a><br />
            <u>Kelly W. Zhang</u>, Omer Gottesman, Finale Doshi-Velez<br />
            <i>Challenges of Real-World Reinforcement Learning 2020 (NeurIPS Workshop)</i><br />
            [<a href="https://arxiv.org/abs/2208.00250" target="_blank" rel="noopener noreferrer">arXiv</a>]
            [<a href="https://sites.google.com/view/neurips2020rwrl#h.ey6lwdtrdt7c" target="_blank" rel="noopener noreferrer">proceedings</a>]
            [<a href="https://www.youtube.com/watch?v=qwslWkKrCRU" target="_blank" rel="noopener noreferrer">video</a>]</p>
            </p>
            
        
        <p><a href="https://aclanthology.org/W18-5448/" target="_blank" rel="noopener noreferrer">Language Modeling Teaches You More Syntax than Translation Does: Lessons Learned Through Auxiliary Task Analysis</a><br />
            Kelly Zhang and Samuel Bowman<br />
            <i>BlackboxNLP 2018 (EMNLP Workshop)</i><br />
            [<a href="https://arxiv.org/abs/1809.10040" target="_blank" rel="noopener noreferrer">arXiv</a>]
            [<a href="https://aclanthology.org/W18-5448/" target="_blank" rel="noopener noreferrer">proceedings</a>]
            </p>
        
        
        <p><a href="http://proceedings.mlr.press/v80/zhao18b.html" target="_blank" rel="noopener noreferrer">Adversarially Regularized Autoencoders</a><br />
            Junbo (Jake) Zhao, Yoon Kim, Kelly Zhang, Alexander Rush, Yann LeCun.<br />
            <i>ICML 2018</i><br />
            [<a href="https://arxiv.org/abs/1706.04223" target="_blank" rel="noopener noreferrer">arXiv</a>]
            [<a href="http://proceedings.mlr.press/v80/zhao18b.html" target="_blank" rel="noopener noreferrer">proceedings</a>]
            [<a href="https://github.com/jakezhaojb/ARAE" target="_blank" rel="noopener noreferrer">code</a>]
            </p>
        
        <hr style="height:1px;width:80%;color:#D3D3Di3;background-color:#D3D3D3">

        <!--
        <br/>
        <h3>Forthcoming Work</h3>
        <ul style="list-style-type:disc">
        <li>
            <p>A Deep Dive into Assessing Personalization after Using Reinforcement Learning<br />
            Raaz Dwivedi*, <u>Kelly W. Zhang</u>*, Prasidh Chhabria, Predrag Klasnja, Susan A. Murphy<br />
            <i>Preparing for submission.</i><br />
            [* means equal contribution]<br />
            </p>
        </li>
            <li>
            <p>[Title redacted; work done during internship at Apple]<br />
            Kelly W Zhang, Sean Jewell, Audra McMillan, Nick Foti<br />
            <i>Preparing to submit to Conference on Health, Inference, and Learning (CHIL).</i><br />
            </p>
        </li>
        <li>
            <p>Optimizing Intervention Components of a Holistic Smartphone Intervention: Protocol of a Microrandomized Trial<br />
            Roman Keller, Oscar Castro, Kelly W Zhang, Prabhakaran Santhanam, Varun Mishra, Jacqueline Mair, Tobias Kowatsch, von Wangenheim Florian<br />
            <i>Preparing for submission.</i><br />
            </p>
        </li>-->
        </ul>

        <h2 class="small">Technical Notes</h2>
        <ul style="list-style-type:disc">
            <li> <a href="assets/threesample.pdf">Why the sample mean can be biased on adaptively collected data (three sample illustration)</a></li>
            <li> <a href="assets/LSVI_notes.pdf">Finite horizon RL and Least-Squares Value Iteration</a></li>
            <li> <a href="assets/Least_squares_methods_rl.pdf">Least-Squares Methods in Batch RL</a></li>
            <!--<li> <a href="assets/class_notes_2_12KellyZhang.pdf">Temporal Difference Methods</a></li>-->
        </ul>
    <br />

    <!---
    <section>
        <h2 class="smallcap">writing</h2>

        <ul style="list-style-type:disc">
            <li>What makes inference for reinforcement learning (adaptively sampled data) challenging?
            [<a href="https://github.com/kellywzhang/kellywzhang.github.io/raw/master/writing/adaptive/adaptive.pdf">pdf</a>]</li>
        </ul>
    </section>
    --->

    <!---
    <section>
        <h2 class="smallcap">presentations</h2>
        <ul style="list-style-type:disc">
            <li>August 2020, I presented our work on Inference for Batched Bandits at the <a href="https://www.worldsymposium2020.org/">Bernoulli World One Symposium</a>.</li>
        </ul>
    </section>
    --->

    <!---
    <section>
        <h2 class="smallcap">mentoring</h2>
        <ul style="list-style-type:disc">
            <li><a href="http://home.ustc.edu.cn/~jiazeyang/">Zeyang Jia</a> (Summer 2020) Weighting methods for maximizing power on adaptively collected data.</li>
            <li><a href="https://www.linkedin.com/in/raymond-feng-4a3473195">Raymond Feng</a> (Spring 2020) Predicting user disengagement among users of <a href="https://www.trackyourtinnitus.org/">Track Your Tinnitus</a>.</li>
        </ul>
    </section>
            <li>January 2022: I helping with the literature review to prepare for a <a href="https://www.radcliffe.harvard.edu/opportunities-for-researchers/2022-exploratory-seminars/ethical-considerations" target="_blank" rel="noopener noreferrer">Radcliffe Institute Exploratory Seminar on ``Ethical Considerations in the Use of Big Data, AI, and Real-Time Information for Prediction of Behavioral Health Outcomes''</a> organized by Jordan Smoller and Matthew Nock.



    <section>
    <br />
        <h2 class="smallcap">Notes</h2>
        <ul style="list-style-type:disc">
            <li> <a href="assets/threesample.pdf">Why the sample mean can be biased on adaptively collected data (three sample illustration)</a></li>
            <li> <a href="assets/LSVI_notes.pdf">Finite horizon RL and Least-Squares Value Iteration</a></li>
            <li> <a href="assets/Least_squares_methods_rl.pdf">Least-Squares Methods in Batch RL</a></li>
            <li> <a href="assets/class_notes_2_12KellyZhang.pdf">Temporal Difference Methods</a></li>
        </ul>
    <br />
    --->

    </section>

